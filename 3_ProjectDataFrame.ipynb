{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0752046a",
   "metadata": {},
   "source": [
    "**Imports and Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       # data manipulation\n",
    "import numpy as np        # numerical operations\n",
    "import re                 # regular expressions\n",
    "from pathlib import Path  # handle filesystem paths\n",
    "\n",
    "# function to load excel file and print rows and columns\n",
    "def load_excel(path: Path, filename: str):\n",
    "    file = path / filename                          # create full path\n",
    "    if not file.exists():                           # check if file exists\n",
    "        raise FileNotFoundError(f\"File not found: {file}\")\n",
    "    df = pd.read_excel(file, engine=\"openpyxl\")     # read excel file with openpyxl\n",
    "    print(f\"Loaded {filename}: {df.shape[0]} rows, {df.shape[1]} cols\")\n",
    "    return df\n",
    "\n",
    "# function to normalize text columns with a list of steps\n",
    "def normalize_columns(df: pd.DataFrame, transformations: dict):\n",
    "    for col, steps in transformations.items():        # iterate over column and steps\n",
    "        if col not in df.columns:                     # skip if column not present\n",
    "            continue\n",
    "        s = df[col].astype(\"string\")                  # convert column to string dtype\n",
    "        for step in steps:                            # iterate transformations\n",
    "            if isinstance(step, str):\n",
    "                if step == \"strip\":\n",
    "                    s = s.str.strip()                # remove leading/trailing spaces\n",
    "                elif step == \"lower\":\n",
    "                    s = s.str.lower()                # convert to lowercase\n",
    "                elif step == \"upper\":\n",
    "                    s = s.str.upper()                # convert to uppercase\n",
    "                elif step == \"title\":\n",
    "                    s = s.str.title()                # title case\n",
    "                else:\n",
    "                    if hasattr(s.str, step):        # fallback for other string methods\n",
    "                        s = getattr(s.str, step)()\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown step '{step}' for column {col}\")\n",
    "            elif isinstance(step, (tuple, list)) and step[0] == \"replace\":\n",
    "                _, pat, repl, *rest = step\n",
    "                regex = rest[0] if rest else False\n",
    "                s = s.str.replace(pat, repl, regex=regex)   # replace pattern\n",
    "            elif callable(step):\n",
    "                try:\n",
    "                    res = step(s)                     # try vectorized\n",
    "                    if isinstance(res, (pd.Series, np.ndarray, list)):\n",
    "                        s = pd.Series(res, index=s.index)\n",
    "                    else:\n",
    "                        s = s.apply(step)\n",
    "                except Exception:\n",
    "                    s = s.apply(step)                 # fallback to apply\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported transformation step: \" + repr(step))\n",
    "        df[col] = s                                  # assign back to df\n",
    "    return df\n",
    "\n",
    "# split comma-separated strings into list and strip spaces\n",
    "def split_and_strip(s):\n",
    "    if pd.isna(s) or str(s).strip() == '':\n",
    "        return []\n",
    "    return [item.strip() for item in str(s).split(',') if item.strip() != '']\n",
    "\n",
    "# unified slug extraction from url for both movies and sales\n",
    "def make_slug(series: pd.Series) -> pd.Series:\n",
    "    s = series.fillna('').astype(str).str.strip().str.lower()\n",
    "    s = s.str.replace(r'\\?.*$', '', regex=True)       # remove query params\n",
    "    s = s.str.extract(r'/([^/]+)/?$')[0]             # take last part of url\n",
    "    s = (\n",
    "        s.str.replace('-', ' ', regex=False)         # replace dashes with spaces\n",
    "         .str.replace(r'\\(.*?\\)', '', regex=True)    # remove parentheses like (2000)\n",
    "         .str.strip()\n",
    "         .str.title()\n",
    "    )\n",
    "    s = s.replace({'': np.nan})\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b11f5",
   "metadata": {},
   "source": [
    "**Process Movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02366f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metaClean43Brightspace.xlsx: 11364 rows, 13 cols\n",
      "\n",
      "Movies - URLs before and after slug extraction:\n",
      "                                                 url  \\\n",
      "0     https://www.metacritic.com/movie/fantasia-2000   \n",
      "1  https://www.metacritic.com/movie/lupin-iii-the...   \n",
      "2       https://www.metacritic.com/movie/next-friday   \n",
      "3       https://www.metacritic.com/movie/my-dog-skip   \n",
      "4         https://www.metacritic.com/movie/supernova   \n",
      "5       https://www.metacritic.com/movie/down-to-you   \n",
      "6  https://www.metacritic.com/movie/things-you-ca...   \n",
      "7     https://www.metacritic.com/movie/the-big-tease   \n",
      "8           https://www.metacritic.com/movie/the-cup   \n",
      "9          https://www.metacritic.com/movie/santitos   \n",
      "\n",
      "                                         slug  \n",
      "0                               Fantasia 2000  \n",
      "1          Lupin Iii The Castle Of Cagliostro  \n",
      "2                                 Next Friday  \n",
      "3                                 My Dog Skip  \n",
      "4                                   Supernova  \n",
      "5                                 Down To You  \n",
      "6  Things You Can Tell Just By Looking At Her  \n",
      "7                               The Big Tease  \n",
      "8                                     The Cup  \n",
      "9                                    Santitos  \n",
      "Movies: rows,cols (11364, 14)\n",
      "Unique slugs: 11364\n",
      "Example titles and ratings:\n",
      "                                        title rating\n",
      "0                               Fantasia 2000      G\n",
      "1         Lupin Iii: The Castle Of Cagliostro  PG-13\n",
      "2                                 Next Friday      R\n",
      "3                                 My Dog Skip     PG\n",
      "4                                   Supernova      R\n",
      "5                                 Down To You  PG-13\n",
      "6  Things You Can Tell Just By Looking At Her  PG-13\n",
      "7                               The Big Tease      R\n",
      "8                                     The Cup      G\n",
      "9                                    Santitos      R\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\")\n",
    "\n",
    "df = load_excel(base_path, \"metaClean43Brightspace.xlsx\")  # load movies data\n",
    "\n",
    "if 'summary' in df.columns:\n",
    "    df_clean = df.drop(columns=['summary']).copy()  # drop summary column\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "\n",
    "# normalize columns\n",
    "df_clean = normalize_columns(df_clean, {\n",
    "    \"title\": [\"strip\", \"title\"],\n",
    "    \"studio\": [\"strip\", \"title\"],\n",
    "    \"rating\": [\"strip\", \"upper\"]   # will remove \"| \" separately\n",
    "})\n",
    "\n",
    "# remove leading \"| \" in rating\n",
    "if 'rating' in df_clean.columns:\n",
    "    df_clean['rating'] = df_clean['rating'].str.replace(r'^\\|\\s*', '', regex=True)\n",
    "\n",
    "# create movie_id sorted by release date if exists\n",
    "if 'RelDate' in df_clean.columns:\n",
    "    df_clean = df_clean.sort_values('RelDate').reset_index(drop=True)\n",
    "else:\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean['movie_id'] = range(1, len(df_clean) + 1)\n",
    "\n",
    "# convert cast and genre columns into lists\n",
    "if 'cast' in df_clean.columns:\n",
    "    df_clean['cast'] = df_clean['cast'].apply(split_and_strip)\n",
    "if 'genre' in df_clean.columns:\n",
    "    df_clean['genre'] = df_clean['genre'].apply(split_and_strip)\n",
    "\n",
    "# apply unified slug function\n",
    "if 'url' in df_clean.columns:\n",
    "    df_clean['slug'] = make_slug(df_clean['url'])\n",
    "    print(\"\\nMovies - URLs before and after slug extraction:\")\n",
    "    print(df_clean[['url', 'slug']].head(10))\n",
    "\n",
    "# prints for verification\n",
    "print(\"Movies: rows,cols\", df_clean.shape)\n",
    "print(\"Unique slugs:\", df_clean['slug'].nunique(dropna=True) if 'slug' in df_clean else 0)\n",
    "print(\"Example titles and ratings:\")\n",
    "print(df_clean[['title','rating']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98d56f",
   "metadata": {},
   "source": [
    "**Sales Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606cf407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sales_movies.xlsx: 30612 rows, 16 cols\n",
      "\n",
      "Sales - URLs before and after slug extraction:\n",
      "                                                 url  \\\n",
      "0  https://www.the-numbers.com/movie/Bakha-Satang...   \n",
      "1  https://www.the-numbers.com/movie/Looking-for-...   \n",
      "2      https://www.the-numbers.com/movie/Kurukshetra   \n",
      "3  https://www.the-numbers.com/movie/Little-Nicky...   \n",
      "4     https://www.the-numbers.com/movie/Suzhou-River   \n",
      "5  https://www.the-numbers.com/movie/Possible-Worlds   \n",
      "6  https://www.the-numbers.com/movie/Me-and-Isaac...   \n",
      "7    https://www.the-numbers.com/movie/Angels-Ladies   \n",
      "8  https://www.the-numbers.com/movie/Charlies-Angels   \n",
      "9  https://www.the-numbers.com/movie/Legend-of-Ba...   \n",
      "\n",
      "                         slug  \n",
      "0                Bakha Satang  \n",
      "1         Looking For An Echo  \n",
      "2                 Kurukshetra  \n",
      "3                Little Nicky  \n",
      "4                Suzhou River  \n",
      "5             Possible Worlds  \n",
      "6         Me And Isaac Newton  \n",
      "7               Angels Ladies  \n",
      "8             Charlies Angels  \n",
      "9  Legend Of Bagger Vance The  \n",
      "\n",
      "Number of non-matching slugs: 23699\n",
      "First 10 non-matching slugs:\n",
      "['Bakha Satang', 'Kurukshetra', 'Possible Worlds', 'Me And Isaac Newton', 'Angels Ladies', 'Legend Of Bagger Vance The', '2 Manner 2 Frauen 4 Probleme', 'Venus Beauty Institute', 'Mercy Streets', 'Kikujiro']\n",
      "Total non-matching slugs: 23699\n",
      "\n",
      "Number of duplicated slugs in merge: 581\n",
      "Duplicated slugs list:\n",
      "                              slug  movie_id\n",
      "2                      Kurukshetra       NaN\n",
      "8                  Charlies Angels     302.0\n",
      "10                        Restless     316.0\n",
      "11                       Blue Moon     308.0\n",
      "23                        Non Stop     312.0\n",
      "...                            ...       ...\n",
      "27909  Hababam Sinifi Yaz Oyunlari       NaN\n",
      "28020    Cuidado Con Lo Que Deseas       NaN\n",
      "29462                      Warning       NaN\n",
      "29665                    Swan Song   11143.0\n",
      "29923                          Val   11124.0\n",
      "\n",
      "[581 rows x 2 columns]\n",
      "\n",
      "🔎 Sales table after assigning movie_id via slug merge:\n",
      " sales_id                         slug  movie_id\n",
      "        1                 Bakha Satang       NaN\n",
      "        2          Looking For An Echo     314.0\n",
      "        3                  Kurukshetra       NaN\n",
      "        4                 Little Nicky     313.0\n",
      "        5                 Suzhou River     309.0\n",
      "        6              Possible Worlds       NaN\n",
      "        7          Me And Isaac Newton       NaN\n",
      "        8                Angels Ladies       NaN\n",
      "        9              Charlies Angels     302.0\n",
      "       10   Legend Of Bagger Vance The       NaN\n",
      "       11                     Restless     316.0\n",
      "       12                    Blue Moon     308.0\n",
      "       13 2 Manner 2 Frauen 4 Probleme       NaN\n",
      "       14             Boesman And Lena     304.0\n",
      "       15       Venus Beauty Institute       NaN\n",
      "       16                Mercy Streets       NaN\n",
      "       17                       Kippur     303.0\n",
      "       18                     Kikujiro       NaN\n",
      "       19                Shanghai Noon     126.0\n",
      "       20              Passion Of Mind     127.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_sales = load_excel(base_path, \"sales_movies.xlsx\")  # load sales data\n",
    "\n",
    "# drop unnecessary columns if they exist\n",
    "to_drop = ['Unnamed: 8','opening_weekend', 'theatre_count','avg run per theatre', 'creative_type']\n",
    "df_sales_clean = df_sales.drop(columns=[c for c in to_drop if c in df_sales.columns]).copy()\n",
    "df_sales_clean.columns = df_sales_clean.columns.str.strip()  # clean column names\n",
    "\n",
    "# create sales_id sorted by year\n",
    "df_sales_clean = df_sales_clean.sort_values('year').reset_index(drop=True)\n",
    "df_sales_clean['sales_id'] = range(1, len(df_sales_clean) + 1)\n",
    "\n",
    "# apply unified slug function\n",
    "if 'url' in df_sales_clean.columns:\n",
    "    df_sales_clean['slug'] = make_slug(df_sales_clean['url'])\n",
    "    print(\"\\nSales - URLs before and after slug extraction:\")\n",
    "    print(df_sales_clean[['url', 'slug']].head(10))\n",
    "\n",
    "# --- Merge sales with movies using slug ---\n",
    "df_sales_merged = df_sales_clean.merge(\n",
    "    df_clean[['movie_id', 'title', 'slug']] if 'title' in df_clean.columns else df_clean[['movie_id', 'slug']],\n",
    "    on='slug',\n",
    "    how='left'  # keep all sales, even if no match\n",
    ")\n",
    "\n",
    "# --- Check 1: Non-matches (sales that didn't find a movie_id) ---\n",
    "non_matches = df_sales_merged[df_sales_merged['movie_id'].isna()]\n",
    "print(f\"\\nNumber of non-matching slugs: {len(non_matches)}\")\n",
    "if len(non_matches) > 0:\n",
    "    print(\"First 10 non-matching slugs:\")\n",
    "    print(non_matches['slug'].head(10).tolist())\n",
    "    print(f\"Total non-matching slugs: {len(non_matches)}\")\n",
    "\n",
    "# --- Check 2: Duplicates (slugs that matched multiple movie_ids) ---\n",
    "dup_sales = df_sales_merged[df_sales_merged.duplicated(subset=['slug'], keep=False)]\n",
    "print(f\"\\nNumber of duplicated slugs in merge: {dup_sales['slug'].nunique()}\")\n",
    "if len(dup_sales) > 0:\n",
    "    print(\"Duplicated slugs list:\")\n",
    "    print(dup_sales[['slug', 'movie_id']].drop_duplicates())\n",
    "\n",
    "# assign back movie_id to clean sales table\n",
    "df_sales_clean['movie_id'] = df_sales_merged['movie_id']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DtaBaseProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
