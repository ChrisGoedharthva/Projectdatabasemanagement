{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039e2d9f",
   "metadata": {},
   "source": [
    "Fifth Draft- Tried again to match the movies id through the slugs of the urls, but this time generating the movie id from the merge dataframe with the slugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656bf81",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af5fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       # data manipulation\n",
    "import numpy as np        # numerical operations\n",
    "import re                 # regular expressions\n",
    "from pathlib import Path  # handle filesystem paths\n",
    "\n",
    "# function to load excel file and print rows and columns\n",
    "def load_excel(path: Path, filename: str):\n",
    "    file = path / filename                          # create full path\n",
    "    if not file.exists():                           # check if file exists\n",
    "        raise FileNotFoundError(f\"File not found: {file}\")\n",
    "    df = pd.read_excel(file, engine=\"openpyxl\")     # read excel file with openpyxl\n",
    "    print(f\"Loaded {filename}: {df.shape[0]} rows, {df.shape[1]} cols\")\n",
    "    return df\n",
    "\n",
    "# function to normalize text columns with a list of steps\n",
    "def normalize_columns(df: pd.DataFrame, transformations: dict):\n",
    "    for col, steps in transformations.items():        # iterate over column and steps\n",
    "        if col not in df.columns:                     # skip if column not present\n",
    "            continue\n",
    "        s = df[col].astype(\"string\")                  # convert column to string dtype\n",
    "        for step in steps:                            # iterate transformations\n",
    "            if isinstance(step, str):\n",
    "                if step == \"strip\":\n",
    "                    s = s.str.strip()                # remove leading/trailing spaces\n",
    "                elif step == \"lower\":\n",
    "                    s = s.str.lower()                # convert to lowercase\n",
    "                elif step == \"upper\":\n",
    "                    s = s.str.upper()                # convert to uppercase\n",
    "                elif step == \"title\":\n",
    "                    s = s.str.title()                # title case\n",
    "                else:\n",
    "                    if hasattr(s.str, step):        # fallback for other string methods\n",
    "                        s = getattr(s.str, step)()\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown step '{step}' for column {col}\")\n",
    "            elif isinstance(step, (tuple, list)) and step[0] == \"replace\":\n",
    "                _, pat, repl, *rest = step\n",
    "                regex = rest[0] if rest else False\n",
    "                s = s.str.replace(pat, repl, regex=regex)   # replace pattern\n",
    "            elif callable(step):\n",
    "                try:\n",
    "                    res = step(s)                     # try vectorized\n",
    "                    if isinstance(res, (pd.Series, np.ndarray, list)):\n",
    "                        s = pd.Series(res, index=s.index)\n",
    "                    else:\n",
    "                        s = s.apply(step)\n",
    "                except Exception:\n",
    "                    s = s.apply(step)                 # fallback to apply\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported transformation step: \" + repr(step))\n",
    "        df[col] = s                                  # assign back to df\n",
    "    return df\n",
    "\n",
    "# split comma-separated strings into list and strip spaces\n",
    "def split_and_strip(s):\n",
    "    if pd.isna(s) or str(s).strip() == '':\n",
    "        return []\n",
    "    return [item.strip() for item in str(s).split(',') if item.strip() != '']\n",
    "\n",
    "# unified slug extraction from url for both movies and sales\n",
    "def make_slug(series: pd.Series) -> pd.Series:\n",
    "    s = series.fillna('').astype(str).str.strip().str.lower()\n",
    "    s = s.str.replace(r'\\?.*$', '', regex=True)       # remove query params\n",
    "    s = s.str.extract(r'/([^/]+)/?$')[0]             # take last part of url\n",
    "    s = (\n",
    "        s.str.replace('-', ' ', regex=False)         # replace dashes with spaces\n",
    "         .str.replace(r'\\(.*?\\)', '', regex=True)    # remove parentheses like (2000)\n",
    "         .str.strip()\n",
    "         .str.title()\n",
    "    )\n",
    "    s = s.replace({'': np.nan})\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478c446",
   "metadata": {},
   "source": [
    "**Process Movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d04a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metaClean43Brightspace.xlsx: 11364 rows, 13 cols\n",
      "\n",
      "Movies - URLs before and after slug extraction:\n",
      "                                                 url  \\\n",
      "0     https://www.metacritic.com/movie/fantasia-2000   \n",
      "1  https://www.metacritic.com/movie/lupin-iii-the...   \n",
      "2       https://www.metacritic.com/movie/next-friday   \n",
      "3       https://www.metacritic.com/movie/my-dog-skip   \n",
      "4         https://www.metacritic.com/movie/supernova   \n",
      "5       https://www.metacritic.com/movie/down-to-you   \n",
      "6  https://www.metacritic.com/movie/things-you-ca...   \n",
      "7     https://www.metacritic.com/movie/the-big-tease   \n",
      "8           https://www.metacritic.com/movie/the-cup   \n",
      "9          https://www.metacritic.com/movie/santitos   \n",
      "\n",
      "                                         slug  \n",
      "0                               Fantasia 2000  \n",
      "1          Lupin Iii The Castle Of Cagliostro  \n",
      "2                                 Next Friday  \n",
      "3                                 My Dog Skip  \n",
      "4                                   Supernova  \n",
      "5                                 Down To You  \n",
      "6  Things You Can Tell Just By Looking At Her  \n",
      "7                               The Big Tease  \n",
      "8                                     The Cup  \n",
      "9                                    Santitos  \n",
      "Movies: rows,cols (11364, 13)\n",
      "Unique slugs: 11364\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\")\n",
    "\n",
    "df = load_excel(base_path, \"metaClean43Brightspace.xlsx\")  # load movies data\n",
    "\n",
    "if 'summary' in df.columns:\n",
    "    df_clean = df.drop(columns=['summary']).copy()  # drop summary column\n",
    "else:\n",
    "    df_clean = df.copy()\n",
    "\n",
    "# normalize columns\n",
    "df_clean = normalize_columns(df_clean, {\n",
    "    \"title\": [\"strip\", \"title\"],\n",
    "    \"studio\": [\"strip\", \"title\"],\n",
    "    \"rating\": [\"strip\", \"upper\"]   # will remove \"| \" separately\n",
    "})\n",
    "\n",
    "# remove leading \"| \" in rating\n",
    "if 'rating' in df_clean.columns:\n",
    "    df_clean['rating'] = df_clean['rating'].str.replace(r'^\\|\\s*', '', regex=True)\n",
    "\n",
    "# sort by release date if exists\n",
    "if 'RelDate' in df_clean.columns:\n",
    "    df_clean = df_clean.sort_values('RelDate').reset_index(drop=True)\n",
    "else:\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# apply unified slug function from URLs\n",
    "if 'url' in df_clean.columns:\n",
    "    df_clean['slug'] = make_slug(df_clean['url'])  # create slug from movie URLs\n",
    "    print(\"\\nMovies - URLs before and after slug extraction:\")\n",
    "    print(df_clean[['url', 'slug']].head(10))\n",
    "\n",
    "# convert cast and genre columns into lists\n",
    "if 'cast' in df_clean.columns:\n",
    "    df_clean['cast'] = df_clean['cast'].apply(split_and_strip)\n",
    "if 'genre' in df_clean.columns:\n",
    "    df_clean['genre'] = df_clean['genre'].apply(split_and_strip)\n",
    "\n",
    "# prints for verification\n",
    "print(\"Movies: rows,cols\", df_clean.shape)\n",
    "print(\"Unique slugs:\", df_clean['slug'].nunique(dropna=True) if 'slug' in df_clean else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec383ad",
   "metadata": {},
   "source": [
    "**Process Sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7f187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sales_movies.xlsx: 30612 rows, 16 cols\n",
      "Sales: rows,cols (30612, 13)\n",
      "Unique slugs: 29944\n"
     ]
    }
   ],
   "source": [
    "df_sales = load_excel(base_path, \"sales_movies.xlsx\")  # load sales data\n",
    "\n",
    "# drop unnecessary columns if they exist\n",
    "to_drop = ['Unnamed: 8','opening_weekend', 'theatre_count','avg run per theatre', 'creative_type']\n",
    "df_sales_clean = df_sales.drop(columns=[c for c in to_drop if c in df_sales.columns]).copy()\n",
    "df_sales_clean.columns = df_sales_clean.columns.str.strip()  # clean column names\n",
    "\n",
    "# sort by year\n",
    "df_sales_clean = df_sales_clean.sort_values('year').reset_index(drop=True)\n",
    "df_sales_clean['sales_id'] = range(1, len(df_sales_clean) + 1)\n",
    "\n",
    "# apply unified slug function from URLs\n",
    "if 'url' in df_sales_clean.columns:\n",
    "    df_sales_clean['slug'] = make_slug(df_sales_clean['url'])  # create slug from sales URLs\n",
    "    #print(\"\\nSales - URLs before and after slug extraction:\")\n",
    "    #print(df_sales_clean[['url', 'slug']].head(10))\n",
    "\n",
    "# prints for verification\n",
    "print(\"Sales: rows,cols\", df_sales_clean.shape)\n",
    "print(\"Unique slugs:\", df_sales_clean['slug'].nunique(dropna=True) if 'slug' in df_sales_clean else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa237f7",
   "metadata": {},
   "source": [
    "**Merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5f6eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of non-matching slugs: 1\n",
      "First 10 non-matching slugs:\n",
      "[nan]\n",
      "\n",
      "Number of duplicated slugs in merge: 0\n",
      "\n",
      "Sales table with slugs and movie_id:\n",
      "                            slug  movie_id\n",
      "0                   Bakha Satang         1\n",
      "1            Looking For An Echo         2\n",
      "2                    Kurukshetra         3\n",
      "3                   Little Nicky         4\n",
      "4                   Suzhou River         5\n",
      "5                Possible Worlds         6\n",
      "6            Me And Isaac Newton         7\n",
      "7                  Angels Ladies         8\n",
      "8                Charlies Angels         9\n",
      "9     Legend Of Bagger Vance The        10\n",
      "10                      Restless        11\n",
      "11                     Blue Moon        12\n",
      "12  2 Manner 2 Frauen 4 Probleme        13\n",
      "13              Boesman And Lena        14\n",
      "14        Venus Beauty Institute        15\n",
      "15                 Mercy Streets        16\n",
      "16                        Kippur        17\n",
      "17                      Kikujiro        18\n",
      "18                 Shanghai Noon        19\n",
      "19               Passion Of Mind        20\n",
      "Excel file created: C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\\movies_slugs.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Merge sales with movies using slug only\n",
    "df_merged = df_sales_clean.merge(\n",
    "    df_clean[['slug']],   # only bring slug from movies\n",
    "    on='slug',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#Assign movie_id based on unique slugs in merged dataset\n",
    "df_merged = df_merged.drop_duplicates(subset=['slug']).reset_index(drop=True)\n",
    "df_merged['movie_id'] = range(1, len(df_merged) + 1)\n",
    "\n",
    "#Check 1: Non-matches (sales slugs not found in movies)\n",
    "non_matches = df_merged[df_merged['slug'].isna()]\n",
    "print(f\"\\nNumber of non-matching slugs: {len(non_matches)}\")\n",
    "if len(non_matches) > 0:\n",
    "    print(\"First 10 non-matching slugs:\")\n",
    "    print(non_matches['slug'].head(10).tolist())\n",
    "\n",
    "#Check 2: Duplicates (slugs appearing multiple times)\n",
    "dup_slugs = df_merged[df_merged.duplicated(subset=['slug'], keep=False)]\n",
    "print(f\"\\nNumber of duplicated slugs in merge: {dup_slugs['slug'].nunique()}\")\n",
    "\n",
    "#Assign back movie_id to sales table\n",
    "df_sales_clean = df_sales_clean.merge(\n",
    "    df_merged[['slug', 'movie_id']],\n",
    "    on='slug',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"\\nSales table with slugs and movie_id:\")\n",
    "print(df_sales_clean[['slug', 'movie_id']].head(20))\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#Define output path and filename\n",
    "output_path = Path(r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\")\n",
    "output_file = output_path / \"movies_slugs.xlsx\"\n",
    "\n",
    "#Select only movie_id and slug columns\n",
    "df_export = df_merged[['movie_id', 'slug']]\n",
    "\n",
    "#Save to Excel\n",
    "df_export.to_excel(output_file, index=False, engine='openpyxl')\n",
    "print(f\"Excel file created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099b981",
   "metadata": {},
   "source": [
    "**Holiday_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b434db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded holidays_tabledf.xlsx: 9 rows, 9 cols\n",
      "Movies with holiday_id assigned:\n",
      "                                         title    RelDate holiday_id\n",
      "0                                Fantasia 2000 2000-01-01          3\n",
      "1          Lupin Iii: The Castle Of Cagliostro 2000-01-01          3\n",
      "2                                  Next Friday 2000-01-12       <NA>\n",
      "3                                  My Dog Skip 2000-01-12       <NA>\n",
      "4                                    Supernova 2000-01-14       <NA>\n",
      "5                                  Down To You 2000-01-21       <NA>\n",
      "6   Things You Can Tell Just By Looking At Her 2000-01-22       <NA>\n",
      "7                                The Big Tease 2000-01-28       <NA>\n",
      "8                                      The Cup 2000-01-28       <NA>\n",
      "9                                     Santitos 2000-01-28       <NA>\n",
      "10                             Isn'T She Great 2000-01-28       <NA>\n",
      "11                               Grizzly Falls 2000-01-28       <NA>\n",
      "12                         Eye Of The Beholder 2000-01-28       <NA>\n",
      "13                                     Gun Shy 2000-02-04       <NA>\n",
      "14                                    Scream 3 2000-02-04       <NA>\n",
      "15                                    Knockout 2000-02-04       <NA>\n",
      "16                                 Cotton Mary 2000-02-11          5\n",
      "17                                   The Beach 2000-02-11          5\n",
      "18                Sex: The Annabel Chong Story 2000-02-11          5\n",
      "19                            The Tigger Movie 2000-02-11          5\n"
     ]
    }
   ],
   "source": [
    "# Load holiday table using the existing function\n",
    "df_holiday = load_excel(base_path, \"holidays_tabledf.xlsx\")\n",
    "\n",
    "# Extract day and month from RelDate in df_clean\n",
    "# RelDate format assumed: DD/MM/YYYY\n",
    "df_clean['RelDate_day'] = pd.to_datetime(df_clean['RelDate'], dayfirst=True).dt.day\n",
    "df_clean['RelDate_month'] = pd.to_datetime(df_clean['RelDate'], dayfirst=True).dt.month\n",
    "\n",
    "# Initialize holiday_id column\n",
    "df_clean['holiday_id'] = pd.NA\n",
    "\n",
    "# Loop through each holiday and assign holiday_id if release date falls within the holiday range\n",
    "for _, holiday in df_holiday.iterrows():\n",
    "    # Extract holiday info\n",
    "    start_day = holiday['start_date day']\n",
    "    start_month = holiday['start_date_month']\n",
    "    end_day = holiday['end_date_day']\n",
    "    end_month = holiday['end_date_month']\n",
    "    hid = holiday['holiday_id']\n",
    "    \n",
    "    # Boolean mask for movies within holiday period\n",
    "    # If holiday spans within the same month\n",
    "    if start_month == end_month:\n",
    "        mask = (\n",
    "            (df_clean['RelDate_month'] == start_month) &\n",
    "            (df_clean['RelDate_day'] >= start_day) &\n",
    "            (df_clean['RelDate_day'] <= end_day)\n",
    "        )\n",
    "    else:  # holiday spans two months\n",
    "        mask = (\n",
    "            ((df_clean['RelDate_month'] == start_month) & (df_clean['RelDate_day'] >= start_day)) |\n",
    "            ((df_clean['RelDate_month'] == end_month) & (df_clean['RelDate_day'] <= end_day))\n",
    "        )\n",
    "    \n",
    "    # Assign holiday_id to movies that fall in this holiday period\n",
    "    df_clean.loc[mask, 'holiday_id'] = hid\n",
    "\n",
    "# Check results\n",
    "print(\"Movies with holiday_id assigned:\")\n",
    "print(df_clean[['title', 'RelDate', 'holiday_id']].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f99849",
   "metadata": {},
   "source": [
    "**Genre_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f02177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with genre_ids assigned:\n",
      "                                         title  \\\n",
      "0                                Fantasia 2000   \n",
      "1          Lupin Iii: The Castle Of Cagliostro   \n",
      "2                                  Next Friday   \n",
      "3                                  My Dog Skip   \n",
      "4                                    Supernova   \n",
      "5                                  Down To You   \n",
      "6   Things You Can Tell Just By Looking At Her   \n",
      "7                                The Big Tease   \n",
      "8                                      The Cup   \n",
      "9                                     Santitos   \n",
      "10                             Isn'T She Great   \n",
      "11                               Grizzly Falls   \n",
      "12                         Eye Of The Beholder   \n",
      "13                                     Gun Shy   \n",
      "14                                    Scream 3   \n",
      "15                                    Knockout   \n",
      "16                                 Cotton Mary   \n",
      "17                                   The Beach   \n",
      "18                Sex: The Annabel Chong Story   \n",
      "19                            The Tigger Movie   \n",
      "\n",
      "                                      genre         genre_id  \n",
      "0       [Fantasy, Music, Animation, Family]     [1, 2, 3, 4]  \n",
      "1   [Adventure, Fantasy, Animation, Family]     [5, 1, 3, 4]  \n",
      "2                                  [Comedy]              [6]  \n",
      "3                    [Drama, Sport, Family]        [7, 8, 4]  \n",
      "4                        [Sci-Fi, Thriller]   [9, 10, 7, 11]  \n",
      "5                  [Drama, Comedy, Romance]       [7, 6, 11]  \n",
      "6                          [Drama, Romance]          [7, 11]  \n",
      "7                                  [Comedy]              [6]  \n",
      "8                           [Sport, Comedy]           [8, 6]  \n",
      "9                           [Drama, Comedy]           [7, 6]  \n",
      "10             [Biography, Comedy, Romance]      [12, 6, 11]  \n",
      "11                              [Adventure]              [5]  \n",
      "12                      [Mystery, Thriller]         [13, 10]  \n",
      "13                 [Comedy, Romance, Crime]      [6, 11, 14]  \n",
      "14      [Mystery, Thriller, Horror, Comedy]  [13, 10, 15, 6]  \n",
      "15                          [Action, Drama]          [16, 7]  \n",
      "16                                  [Drama]              [7]  \n",
      "17             [Adventure, Drama, Thriller]       [5, 7, 10]  \n",
      "18                            [Documentary]             [17]  \n",
      "19              [Comedy, Animation, Family]        [6, 3, 4]  \n"
     ]
    }
   ],
   "source": [
    "# ---- Sixth cell: Assign genre_id lists to movies ----\n",
    "\n",
    "# Step 1: Rebuild norm_genre to ensure we have genre_id mapping\n",
    "df_genre = df_clean[['title', 'genre']].copy()\n",
    "\n",
    "# Explode genres into separate rows\n",
    "df_genre_exploded = df_genre.explode('genre').dropna()\n",
    "\n",
    "# Create unique genre table with ids (like in norm_genre notebook)\n",
    "norm_genre = df_genre_exploded[['genre']].drop_duplicates().reset_index(drop=True)\n",
    "norm_genre['genre_id'] = range(1, len(norm_genre) + 1)\n",
    "\n",
    "# Step 2: Map genres to genre_id\n",
    "df_genre_exploded = df_genre_exploded.merge(norm_genre, on='genre', how='left')\n",
    "\n",
    "# Step 3: Group back by title to collect all genre_ids per movie\n",
    "genre_ids_per_movie = (\n",
    "    df_genre_exploded.groupby('title')['genre_id']\n",
    "    .apply(list)        # collect genre_ids into a list\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 4: Merge back into df_clean\n",
    "df_clean = df_clean.merge(genre_ids_per_movie, on='title', how='left')\n",
    "\n",
    "# Step 5: Print check\n",
    "print(\"Movies with genre_ids assigned:\")\n",
    "print(df_clean[['title', 'genre', 'genre_id']].head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DtaBaseProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
