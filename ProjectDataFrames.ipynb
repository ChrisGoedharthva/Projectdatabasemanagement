{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d82c733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #for normalicing texts like titles\n",
    "from difflib import get_close_matches #fuzzy matching between strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d630e",
   "metadata": {},
   "source": [
    "**metaClean43Brightspace Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'title', 'studio', 'rating', 'runtime', 'cast', 'director',\n",
      "       'genre', 'summary', 'awards', 'metascore', 'userscore', 'RelDate'],\n",
      "      dtype='object')\n",
      "Index(['url', 'title', 'studio', 'rating', 'runtime', 'cast', 'director',\n",
      "       'genre', 'awards', 'metascore', 'userscore', 'RelDate'],\n",
      "      dtype='object')\n",
      "                                                 url  \\\n",
      "0     https://www.metacritic.com/movie/fantasia-2000   \n",
      "1  https://www.metacritic.com/movie/lupin-iii-the...   \n",
      "2       https://www.metacritic.com/movie/next-friday   \n",
      "3       https://www.metacritic.com/movie/my-dog-skip   \n",
      "4         https://www.metacritic.com/movie/supernova   \n",
      "5       https://www.metacritic.com/movie/down-to-you   \n",
      "6  https://www.metacritic.com/movie/things-you-ca...   \n",
      "7     https://www.metacritic.com/movie/the-big-tease   \n",
      "8           https://www.metacritic.com/movie/the-cup   \n",
      "9          https://www.metacritic.com/movie/santitos   \n",
      "\n",
      "                                        title                 studio rating  \\\n",
      "0                               Fantasia 2000   Buena Vista Pictures      G   \n",
      "1         Lupin Iii: The Castle Of Cagliostro            Eleven Arts  PG-13   \n",
      "2                                 Next Friday        New Line Cinema      R   \n",
      "3                                 My Dog Skip  Warner Bros. Pictures     PG   \n",
      "4                                   Supernova         United Artists      R   \n",
      "5                                 Down To You          Miramax Films  PG-13   \n",
      "6  Things You Can Tell Just By Looking At Her                   Gaga  PG-13   \n",
      "7                               The Big Tease  Warner Bros. Pictures      R   \n",
      "8                                     The Cup         Festival Media      G   \n",
      "9                                    Santitos       New Yorker Films      R   \n",
      "\n",
      "   runtime                                               cast  \\\n",
      "0     74.0                       [James Levine, Steve Martin]   \n",
      "1    100.0  [Eiko Masuyama, GorÃ´ Naya, IchirÃ´ Nagai, Kiy...   \n",
      "2     98.0                                         [Ice Cube]   \n",
      "3     95.0           [Diane Lane, Frankie Muniz, Kevin Bacon]   \n",
      "4     90.0      [James Spader, Peter Facinelli, Robin Tunney]   \n",
      "5     91.0                 [Freddie Prinze Jr., Julia Stiles]   \n",
      "6    109.0  [Amy Brenneman, Calista Flockhart, Cameron Dia...   \n",
      "7     86.0                                                 []   \n",
      "8     93.0                                                 []   \n",
      "9    105.0                                                 []   \n",
      "\n",
      "               director                                    genre  \\\n",
      "0              Don Hahn      [Fantasy, Music, Animation, Family]   \n",
      "1        Hayao Miyazaki  [Adventure, Fantasy, Animation, Family]   \n",
      "2            Steve Carr                                 [Comedy]   \n",
      "3           Jay Russell                   [Drama, Sport, Family]   \n",
      "4  Francis Ford Coppola                       [Sci-Fi, Thriller]   \n",
      "5         Kris Isacsson                 [Drama, Comedy, Romance]   \n",
      "6       Rodrigo GarcÃ­a                         [Drama, Romance]   \n",
      "7           Kevin Allen                                 [Comedy]   \n",
      "8        Khyentse Norbu                          [Sport, Comedy]   \n",
      "9   Alejandro Springall                          [Drama, Comedy]   \n",
      "\n",
      "                        awards  metascore  userscore    RelDate  movie_id  \n",
      "0  #63MostDiscussedMovieof2000         59        7.2 2000-01-01         1  \n",
      "1           #77BestMovieof2000         72        8.1 2000-01-01         2  \n",
      "2     #48MostSharedMovieof2000         41        6.3 2000-01-12         3  \n",
      "3                          NaN         61        7.9 2000-01-12         4  \n",
      "4  #95MostDiscussedMovieof2000         19        5.8 2000-01-14         5  \n",
      "5                          NaN         13        5.4 2000-01-21         6  \n",
      "6           #43BestMovieof2000         76        NaN 2000-01-22         7  \n",
      "7                          NaN         53        NaN 2000-01-28         8  \n",
      "8           #90BestMovieof2000         70        NaN 2000-01-28         9  \n",
      "9                          NaN         68        NaN 2000-01-28        10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re #for normalicing texts like titles #Max Code\n",
    "from pathlib import Path #Max Code\n",
    "\n",
    "def load_excel(path, filename):\n",
    "    file = path / filename\n",
    "    if not file.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file}\")\n",
    "    return pd.read_excel(file, engine=\"openpyxl\") #openpyxl for efficiency in excel files\n",
    "\n",
    "base_path = Path(r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\") \n",
    "\n",
    "#DataFrames: file upload\n",
    "df     = load_excel(base_path, \"metaClean43Brightspace.xlsx\")\n",
    "sales  = load_excel(base_path, \"sales_movies.xlsx\")\n",
    "expert = load_excel(base_path, \"ExpertReviewsClean43LIWC.xlsx\")\n",
    "\n",
    "#paths to save results\n",
    "movies_dataframe= base_path / \"movies_dataframe\"\n",
    "movies_dict_dataframe= base_path / \"movies_dict_dataframe\" #Max Code\n",
    "\n",
    "df.head()\n",
    "print(df.columns)        # Movie\n",
    "\n",
    "df_clean=df.drop(('summary'), axis=1) #Delete column\n",
    "print(df_clean.columns)\n",
    "\n",
    "#normalizing text\n",
    "def normalize_columns(df, transformations):\n",
    "    for col, funcs in transformations.items():  # recorre columnas y funciones\n",
    "        if col in df.columns:\n",
    "            for func in funcs:\n",
    "                if func == \"replace\":\n",
    "                    df[col] = df[col].str.replace(\"| \", \"\", regex=False)\n",
    "                else:\n",
    "                    df[col] = getattr(df[col].str, func)()\n",
    "    return df\n",
    "df_clean = normalize_columns(\n",
    "    df_clean,\n",
    "    {\n",
    "        \"title\": [\"strip\", \"title\"],\n",
    "        \"studio\": [\"strip\", \"title\"],\n",
    "        \"rating\": [\"strip\", \"upper\", \"replace\"]  \n",
    "    }\n",
    ")\n",
    "#print(df_clean[[\"title\", \"studio\", \"rating\"]].head(10))\n",
    "\n",
    "ids_url=[]\n",
    "if 'url' in df_clean.columns:\n",
    "    id_col_mov= 'url'\n",
    "    for u in df_clean['url']:\n",
    "        ids_url.append(u)\n",
    "#print(ids_url) #urls list\n",
    "#print(len(ids_url)) #11,364\n",
    "\n",
    "#movie_id\n",
    "df_clean = df_clean.sort_values('RelDate') #order of ids from Release Date\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean['movie_id'] = range(1, len(df_clean) + 1) #movie_id generation 1...11364\n",
    "\n",
    "#df_clean[['title', 'RelDate', 'url', 'movie_id']].head(10) #Check\n",
    "#print(df_clean['movie_id'].is_unique)   # needs to be TRUE\n",
    "\n",
    "#Funcion that converts a lst if there's sth, if not empty lst\n",
    "def split_and_strip(s):\n",
    "    if pd.isna(s) or str(s).strip() == '': #pd.isna(s) checks if cell empty\n",
    "        return []\n",
    "    return [item.strip() for item in str(s).split(',') if item.strip() != '']  #separate with coma and clean spaces\n",
    "   \n",
    "\n",
    "df_clean['cast'] = df_clean['cast'].apply(split_and_strip) #apply to cast\n",
    "df_clean['genre'] = df_clean['genre'].apply(split_and_strip) #apply to genre\n",
    "\n",
    "#print(df_clean.head(10))\n",
    "#print(df_clean[['title', 'studio', 'rating', 'cast', 'genre']].head(10)) #Check\n",
    "\n",
    "#url_clean: normalice url in df_clean\n",
    "#df_clean['url_clean'] = df_clean['url'].fillna('').astype(str).str.strip().str.lower() #normalice urls\n",
    "#df_clean['url_clean'] = df_clean['url_clean'].replace({'': np.nan}) #recognize empty values as missing data (np.nan)\n",
    "#print(\"Movies - urls unique (non-null):\", df_clean['url_clean'].nunique(dropna=True)) #counts unique values/ dropna=True: ignores Nan(empty) values\n",
    "#print(df_clean['url_clean'][:5])\n",
    "\n",
    "#control duplicates\n",
    "#dups = df_clean['url_clean'].duplicated(keep=False).sum() #(keep=True(1):Duplicates, keep=False(0):NoDuplicates)\n",
    "#print(\"Duplicated url_clean rows in df_clean:\", dups)  # Check\n",
    "#if dups > 0: #show examples of duplicates if they exist\n",
    "#    print(\"\\nExamples of duplicated urls to analyze:\") \n",
    "#    mask = df_clean['url_clean'].duplicated(keep=False)      # boolean series\n",
    "#    dups_df = df_clean[mask]                                 # DF only duplicates\n",
    "#    subset = dups_df[['title', 'url', 'url_clean', 'movie_id']]  #filter columns to analice\n",
    "#    print(subset.head(10))                                   # show first 10 lines\n",
    "\n",
    "#Delete Pending_Dictonary creation url>movie_id (url_to_id)\n",
    "#source = df_clean.drop_duplicates(subset='url_clean', keep='first') #just chooses first url (no duplicates)\n",
    "#url_to_id = dict(zip(source['url_clean'], source['movie_id'])) #zip combines url and id, dict converts into dictionary\n",
    "#print(url_to_id)\n",
    "#print(f\"Dictonary generates with {len(url_to_id)} keys\") #debug\n",
    "#print(list(url_to_id.items())[:5])  #first 5 pairs of key:value\n",
    "\n",
    "#Strip title from url\n",
    "#df_clean['slug'] = df_clean['url'].str.split('/').str[-1].str.strip().str.lower()\n",
    "\n",
    "#save new table in file\n",
    "#df_clean.to_csv(\"movies_clean.csv\", index=False) #in csv perfect for sql\n",
    "#df_clean.to_excel(\"movies_clean.xlsx\", index=False) #in excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901f3c0",
   "metadata": {},
   "source": [
    "**sales_movies Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff580a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total URLs: 30612\n",
      "Sales  - urls unique (non-null): 30612\n",
      "Duplicated url_clean rows in df_clean: 0\n",
      "Mapped by URL: 0 / 30612 rows (0.0%)\n",
      "Ejemplos de url_clean en df_clean: ['https://www.metacritic.com/movie/fantasia-2000', 'https://www.metacritic.com/movie/lupin-iii-the-castle-of-cagliostro', 'https://www.metacritic.com/movie/next-friday', 'https://www.metacritic.com/movie/my-dog-skip', 'https://www.metacritic.com/movie/supernova']\n",
      "Ejemplos de url_clean en df_sales_clean: ['https://www.the-numbers.com/movie/bakha-satang-(s-korea)', 'https://www.the-numbers.com/movie/looking-for-an-echo', 'https://www.the-numbers.com/movie/kurukshetra', 'https://www.the-numbers.com/movie/little-nicky-(2000)', 'https://www.the-numbers.com/movie/suzhou-river']\n",
      "Coincidencias de URL entre ambos datasets: 0\n",
      "Ejemplo de coincidencias: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path2=r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\\sales_movies.xlsx\"\n",
    "df_sales=pd.read_excel(path2) #df_sales = sales info file\n",
    "\n",
    "#df_sales.head()\n",
    "#print(df_sales.columns)  # Sales\n",
    "\n",
    "df_sales_clean=df_sales.drop(['Unnamed: 8','opening_weekend', 'theatre_count','avg run per theatre', 'creative_type'], axis=1) #Delete columns\n",
    "#print(df_sales_clean.columns)\n",
    "\n",
    "df_sales_clean.columns = df_sales_clean.columns.str.strip() #clean column names\n",
    "\n",
    "#print(\"Column names:\") #to see the names of the columns\n",
    "#for col in df_sales_clean.columns:\n",
    "#    print(f\"'{col}'\")\n",
    "\n",
    "#creation url sales list (eliminating nule values)\n",
    "ids_url_sales = df_sales_clean['url'].dropna().tolist()\n",
    "#print(ids_url_sales[:10]) #first 10 urls on lst\n",
    "print(\"Total URLs:\", len(ids_url_sales)) #30,612\n",
    "\n",
    "#sales_id\n",
    "df_sales_clean = df_sales_clean.sort_values('year', ascending=True) #organice in year order\n",
    "df_sales_clean = df_sales_clean.reset_index(drop=True) #Reset index\n",
    "df_sales_clean['sales_id'] = range(1, len(df_sales_clean) + 1) #create sales id column\n",
    "#print(df_sales_clean[['title', 'year', 'release_date', 'url', 'sales_id']].head(10)) #Check\n",
    "\n",
    "#df_clean[['title', 'RelDate', 'url', 'movie_id']].head(10) #Check\n",
    "#print(df_clean['movie_id'].is_unique)   # needs to be TRUE\n",
    "\n",
    "#url_clean: normalice url in df_clean\n",
    "#df_sales_clean['url_clean'] = df_sales_clean['url'].fillna('').astype(str).str.strip().str.lower()\n",
    "#df_sales_clean['url_clean'] = df_sales_clean['url_clean'].replace({'': np.nan})\n",
    "#print(\"Sales  - urls unique (non-null):\", df_sales_clean['url_clean'].nunique(dropna=True))\n",
    "#print(df_sales_clean['url_clean'][:5])\n",
    "\n",
    "#control duplicates\n",
    "#dups = df_clean['url_clean'].duplicated(keep=False).sum() #(keep=True(1):Duplicates, keep=False(0):NoDuplicates)\n",
    "#print(\"Duplicated url_clean rows in df_clean:\", dups)  # Check\n",
    "#if dups > 0: #show examples of duplicates if they exist\n",
    "#    print(\"\\nExamples of duplicated urls to analyze:\") \n",
    "#    mask = df_clean['url_clean'].duplicated(keep=False)      # boolean series\n",
    "#    dups_df = df_clean[mask]                                 # DF only duplicates\n",
    "#    subset = dups_df[['title', 'url', 'url_clean', 'movie_id']]  #filter columns to analice\n",
    "#    print(subset.head(10))                                   # show first 10 lines\n",
    "\n",
    "#Delete pending_Mapping- Dictonary connection url>movie_id (url_to_id)\n",
    "#df_sales_clean['movie_id'] = df_sales_clean['url_clean'].map(url_to_id) #takes sales url and looks a connection in dic with movie_id & creates movie_id column in sales\n",
    "#mapped = df_sales_clean['movie_id'].notna().sum() #count how many matches were done\n",
    "#total = len(df_sales_clean) #total rows in sales\n",
    "#print(f\"Mapped by URL: {mapped} / {total} rows ({mapped/total:.1%})\") #percentage of how many matches were made from tot rows in sales\n",
    "# Debug urls\n",
    "#print(\"Ejemplos de url_clean en df_clean:\", df_clean['url_clean'].dropna().head(5).tolist())\n",
    "#print(\"Ejemplos de url_clean en df_sales_clean:\", df_sales_clean['url_clean'].dropna().head(5).tolist())\n",
    "#common_urls = set(df_clean['url_clean'].dropna()).intersection(df_sales_clean['url_clean'].dropna())\n",
    "#print(f\"Coincidencias de URL entre ambos datasets: {len(common_urls)}\")\n",
    "#print(\"Ejemplo de coincidencias:\", list(common_urls)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b1c46",
   "metadata": {},
   "source": [
    "**ExpertReviewsClean43LIWC Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0880efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#path3=r\"C:\\Users\\dbust\\OneDrive\\Documentos\\Amsterdam_2025\\DDBM\\Database_Management\\Project_DBM\\ExpertReviewsClean43LIWC.xlsx\"\n",
    "#df_ExpRev=pd.read_excel(path3) #df_ExpRev = expert review file\n",
    "\n",
    "#df_ExpRev.head()\n",
    "#print(df_ExpRev.columns) # Expert Reviews\n",
    "\n",
    "#df_clean_ExpRev=df_ExpRev.drop(['Analytic', 'Clout', 'Authentic', 'Sixltr', 'Dic', 'function','ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron',\n",
    "#       'article', 'prep', 'auxverb', 'negate', 'verb', 'adj',\n",
    "#       'compare', 'interrog', 'number', 'quant', 'affect', 'female', 'male','insight', 'cause', 'discrep', 'tentat', 'certain', 'differ',\n",
    "#       'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual',\n",
    "#       'ingest', 'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk',\n",
    "#       'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion',\n",
    "#       'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death',\n",
    "#       'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler',\n",
    "#       'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam',\n",
    "#       'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP', 'conj'], axis=1) #Delete columns\n",
    "#print(df_clean_ExpRev.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DtaBaseProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
