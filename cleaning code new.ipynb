{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2132378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "# to import the tools I need to clean the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d334654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_location = 'C:\\\\Users\\\\chris\\\\Downloads\\\\UserReviewsClean43LIWC.xlsx' #To define and show the location of the file\n",
    "user = pd.read_excel(file_location) #Import the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.drop(columns=[\"dateP\", \"thumbsUp\", \"thumbsTot\", \"Analytic\", \"Clout\", \"Authentic\", \"Tone\", \"Sixltr\", \"Dic\", \n",
    "                      \"function\", \"ppron\", \"i\",\t\"we\", \"you\", \"shehe\", \"they\", \"ipron\", \"article\", \"prep\", \"auxverb\", \n",
    "                      \"adverb\", \"conj\", \"negate\", \"verb\", \"adj\", \"compare\", \"interrog\", \"number\", \"quant\", \"affect\", \n",
    "                      \"family\", \"friend\", \"female\", \"male\", \"insight\", \"cause\", \"discrep\", \"tentat\", \"certain\", \"differ\", \n",
    "                      \"percept\", \"see\", \"hear\", \"feel\", \"bio\", \"body\", \"health\", \"sexual\", \"ingest\", \"drives\", \"affiliation\", \n",
    "                      \"achieve\", \"power\", \"focuspast\", \"focuspresent\", \"focusfuture\",\t\"relativ\", \"motion\", \"space\", \"time\", \n",
    "                      \"work\", \"leisure\", \"home\", \"relig\", \"death\", \"informal\", \"swear\", \"netspeak\", \"assent\", \"nonflu\", \"filler\", \n",
    "                      \"AllPunc\", \"Period\", \"Comma\", \"Colon\", \"SemiC\", \"QMark\", \"Exclam\", \"Dash\", \"Quote\", \"Apostro\", \"Parenth\", \"OtherP\"])\n",
    "#Here I delete the colomns I don't need. The rest of the columns I need I got from the ERD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a24a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.columns = [c.lower() for c in user.columns] #to normalize the column names\n",
    "user = user.drop_duplicates() #to drop duplicates in the file, because somethimes the same review is twice in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b6e9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "user[\"movie name\"] = user[\"url\"].str.split(\"/\").str[-1].str.replace(\"-\", \"\", regex=False)\n",
    "#This is to split the URL and take the last part of the URL (the movie name), and put the movie name into a new column called 'movie name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b9f16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.dropna(thresh=3)\n",
    "#Here it will drop the row if there are more then 3 missing values in the row. Because we want trustworthy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1733a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.replace({'':np.nan}) #Replaces the empty values with NAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e5106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user[user[\"wc\"] >= 5]                                   #Drops the reviews that have less than 5 words\n",
    "user = user[~user[\"rev\"].astype(str).str.match(r'^\\d+$')]      #Drops the reviews that only have numbers in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d654a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file = \"C:\\\\Users\\\\chris\\\\Downloads\\\\movies_slugs.xlsx\"\n",
    "movies = pd.read_excel(movies_file)                                #Here I upload the file with movie slugs and the movie ID\n",
    "\n",
    "user[\"movie name\"] = user[\"movie name\"].astype(str).str.strip().str.lower()\n",
    "movies[\"slug\"] = movies[\"slug\"].astype(str).str.strip().str.lower()                  #this is to normalize all the names\n",
    "\n",
    "user = user.merge(                                                                 #Here I merge the tables together, to get the movie ID\n",
    "    movies[[\"slug\", \"movie_id\"]],                                                  #from the movie_slugs table\n",
    "    left_on=\"movie name\",\n",
    "    right_on=\"slug\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "user = user.drop(columns=[\"slug\"])                                                #Here I delete the slugs because i have the name and the ID\n",
    "                                                                                  #of the movie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4ef9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user[\"user_id\"] = user[\"reviewer\"].astype(str).factorize()[0] + 1 #to create a user ID per unique user that left a review\n",
    "user[\"reviewer\"] = user[\"reviewer\"].astype(str).str.replace(\"'\", \"\", regex=False) #to remove the apostrophes in the reviewers names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd42a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'C:\\\\Users\\\\chris\\\\Downloads\\\\UserReviewsCleanedfirst2.csv' #makes an output file of the clean data sheet\n",
    "user.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104fd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b9cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = 'postgresql://postgres:8536@localhost:5432/postgres' #to make a connection with postgres\n",
    "\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "\n",
    "conn1 = psycopg2.connect(                     #setup a connection and provide the information about the server (local host)\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"8536\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "conn1.autocommit = True\n",
    "cursor = conn1.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('drop table if exists UserReviews') #Dropping the tables that are alreadt exsist\n",
    "\n",
    "sql = \"CREATE TABLE UserReviews(url, idvscore, reviewer, rev, wc, wps, pronoun, posemo, negemo, anx, anger, sad, social, cogproc, reward, risk, money, movie name, movie_id, user_id)\"\n",
    "#creating the table with the columns I want in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb7f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"UserReviewsCleanedfirst2.csv\") #to import the clean file in postgres\n",
    "\n",
    "data = data[[\"url\", \"idvscore\", \"reviewer\", \"rev\", \"wc\", \"wps\", \"pronoun\", \"posemo\", \"negemo\", \"anx\", \"anger\", \"sad\", \"social\", \"cogproc\", \"reward\", \"risk\", \"money\", \"movie name\", \"movie_id\", \"user_id\"]]\n",
    "#this is to create the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1277ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_sql('UserReviews', conn, if_exists= 'replace')\n",
    "#to convert the data into sql, if it already exists it will replace the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6e4018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('postgres',)\n"
     ]
    }
   ],
   "source": [
    "sql1 = \"SELECT * FROM User;\"                #to retrieve all the rows from the datafile\n",
    "cursor.execute(sql1)\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe254436",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1.commit()\n",
    "conn1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythondebeste",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
